{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 11 - Ore and Ice Arbitrage with Limit Orders\n",
    "\n",
    "In this example, we modify our ore and ice arbitrage strategy so that we sell refined material with limit orders when it is more profitable to do so.  This example is a modified version of Example 7, which considered ore and ice arbitrage for a single day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "# EveKit imports\n",
    "from evekit.reference import Client\n",
    "from evekit.util import convert_raw_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using region_id=10000002, station_id=60003760 at 2017-01-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# We'll use a day of order book data for all ore and ice types and their refined materials.\n",
    "# This cell sets up our reference date, region and station.  The next cells derive the appropriate\n",
    "# inventory types and retrieve appropriate market data.\n",
    "#\n",
    "sde_client = Client.SDE.get()\n",
    "region_query = \"{values: ['The Forge']}\"\n",
    "station_query = \"{values: ['Jita IV - Moon 4 - Caldari Navy Assembly Plant']}\"\n",
    "region_id = sde_client.Map.getRegions(regionName=region_query).result()[0][0]['regionID']\n",
    "station_id = sde_client.Station.getStations(stationName=station_query).result()[0][0]['stationID']\n",
    "compute_date = datetime.datetime(2017, 1, 10)\n",
    "print(\"Using region_id=%d, station_id=%d at %s\" % (region_id, station_id, str(compute_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load ore and ice types as well as the materials they can refine to.\n",
    "# Start with ore and ice material groups.\n",
    "#\n",
    "material_group_names = [ 'Veldspar', 'Scordite', 'Pyroxeres', 'Plagioclase', 'Omber', 'Kernite', 'Jaspet', \n",
    "                         'Hemorphite', 'Hedbergite', 'Gneiss', 'Dark Ochre', 'Spodumain', 'Crokite', \n",
    "                         'Bistot', 'Arkonor', 'Mercoxit', 'Ice' ]\n",
    "group_name_query = \"{values:[\" + \",\".join(map(lambda x : \"'\" + x + \"'\", material_group_names)) + \"]}\"\n",
    "material_groups = Client.SDE.load_complete(sde_client.Inventory.getGroups, groupName=group_name_query)\n",
    "\n",
    "# Next, we'll retrieve type information for all the inventory items in the requested groups\n",
    "group_id_query = \"{values:[\" + \",\".join([str(x['groupID']) for x in material_groups]) + \"]}\"\n",
    "source_types = {}\n",
    "for next_type in Client.SDE.load_complete(sde_client.Inventory.getTypes, groupID=group_id_query):\n",
    "    if next_type['marketGroupID'] is not None:\n",
    "        # We perform this check because the 'Ice' family in the SDE includes some non-refinable types\n",
    "        # These are detectable by the lack of a market group ID.  We create a material_map entry\n",
    "        # in preparation for the next step.\n",
    "        next_type['material_map'] = {}\n",
    "        source_types[next_type['typeID']] = next_type\n",
    "\n",
    "# Finally, we'll determine the types which each source material can refine to.  We'll save this information\n",
    "# as a map associated with each source type.\n",
    "type_id_query = \"{values:[\" + \",\".join([str(x) for x in source_types.keys()]) + \"]}\"\n",
    "for next_mat in Client.SDE.load_complete(sde_client.Inventory.getTypeMaterials, typeID=type_id_query):\n",
    "    source_types[next_mat['typeID']]['material_map'][next_mat['materialTypeID']] = next_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up types for which we need market data.\n",
    "#\n",
    "download_types = set(source_types.keys())\n",
    "for next_type in source_types.values():\n",
    "    download_types = download_types.union(next_type['material_map'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving 2017-01-10 00:00:00...done\n"
     ]
    }
   ],
   "source": [
    "# We assume you've already downloaded market data for our sample day.  If you haven't done this, you\n",
    "# can retrieve market data by executing the appropriate cell in  Example 7.  We recommend you always \n",
    "# download order book data, but if you'd rather use online data, you can remove the \"local_storage\" \n",
    "# argument from the order book functions below.  This cell loads order book data for our target day.\n",
    "#\n",
    "from evekit.marketdata import OrderBook\n",
    "order_book = OrderBook.get_data_frame(dates=[compute_date], types=download_types, regions=[region_id], \n",
    "                                      config=dict(local_storage=\".\", tree=True, skip_missing=True, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving 2017-01-10 00:00:00...done\n"
     ]
    }
   ],
   "source": [
    "# Using limit orders instead of market orders when selling materials requires that we control the\n",
    "# size of our limit orders.  Otherwise, we'll simply flood the market with excessive limit orders\n",
    "# which are unlikely to be filled.  We control limit orders by constraining them to be no larger\n",
    "# than a fraction of historic volume.  As a result, we need historic volume for our target day.\n",
    "# If this were a live trading strategy, we'd use recent historic volume (e.g. a weighted average\n",
    "# of recent days) since data for the current day is likely not available.\n",
    "#\n",
    "from evekit.marketdata import MarketHistory\n",
    "market_history = MarketHistory.get_data_frame(dates=[compute_date], types=download_types, regions=[region_id], \n",
    "                                              config=dict(local_storage=\".\", tree=True, skip_missing=True, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need two new configuration parameters when using limit orders:\n",
    "#\n",
    "# 1. broker_rate - this is the percentage fee charged to place market orders\n",
    "# 2. volume_limit - this is the fraction of daily volume we will not exceed for limit orders.\n",
    "#\n",
    "# In addition to setting efficiency,tax rate and station tax, we set these\n",
    "# additional parameters at the end of this cell.\n",
    "\n",
    "# This is the efficiency at a typical NPC station with max skills\n",
    "efficiency = 0.5 * 1.15 * 1.1 * 1.1\n",
    "\n",
    "# This is the sales tax at a typical NPC station with max skills\n",
    "tax_rate = 0.01\n",
    "\n",
    "# Station tax can be no greater than 0.05.  This value is zero if standings are 6.67 or better.\n",
    "# As noted above, we're substituting order price for adjusted price.  From empirical observation,\n",
    "# setting station_tax to 0.04 roughly approximates a station_tax of 0.05 with true adjusted prices.\n",
    "# So we'll set station tax to 0.04 here.\n",
    "station_tax = 0.04\n",
    "\n",
    "# This is the broker rate at a typical NPC station with max skills\n",
    "broker_rate = 0.025\n",
    "\n",
    "# A rule of thumb is that we shouldn't be attempting to sell more than 10% of daily\n",
    "# volume for a partcular asset type.  Since we may be selling across multiple opportunities\n",
    "# in a given day, we reduce this limit even further to 1% per opportunity.\n",
    "volume_limit = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dump opportunities in a nice format.  Note that this dumper also displays whether\n",
    "# any orders were sold as limit orders instead of market orders (see below).\n",
    "def display_opportunities(opps):\n",
    "    for opp in opps:\n",
    "        profit = \"{:15,.2f}\".format(opp['profit'])\n",
    "        margin = \"{:8.2f}\".format(opp['margin'] * 100)\n",
    "        limit = True\n",
    "        print(\"ArbOpp time=%s  profit=%s  return=%s%%  limit=%s  type=%s\" % (str(opp['time']), profit, margin, \n",
    "                                                                             limit, opp['type']))\n",
    "    print(\"Total opportunities: %d\" % len(opps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll move right to optimizing for each opportunity and use the list-based order functions from Example 7.\n",
    "\n",
    "# Attempt to buy from a list of orders which are assumed to already be filtered to sell orders \n",
    "# of the given type and the appropriate location.  This function will consume orders to fill \n",
    "# the given volume, and will return a list of objects {price, volume} showing the orders that \n",
    "# were made.  This list will be empty if we can not fill the order completely.\n",
    "def attempt_buy_type_list(buy_volume, sell_order_list):\n",
    "    potential = []\n",
    "    for next_order in sell_order_list:\n",
    "        if buy_volume >= next_order['min_volume'] and next_order['volume'] > 0:\n",
    "            # Buy into this order\n",
    "            amount = min(buy_volume, next_order['volume'])\n",
    "            order_record = dict(price=next_order['price'], volume=amount, market=True)\n",
    "            buy_volume -= amount\n",
    "            next_order['volume'] -= amount\n",
    "            potential.append(order_record)\n",
    "        if buy_volume == 0:\n",
    "            # We've completely filled this order\n",
    "            return potential\n",
    "    # If we never completely fill the order then return no orders\n",
    "    return []\n",
    "\n",
    "# Attempt to sell to a list of orders which are assumed to already be filtered to buy \n",
    "# orders of the given type.  We use our range checker to implement proper ranged buy \n",
    "# order matching.  This function will consume volume from an order if possible, and \n",
    "# return a list of objects {price, volume} showing the orders that were filled.  This \n",
    "# list will be empty if we can not fill the order completely.\n",
    "from evekit.marketdata import TradingUtil\n",
    "\n",
    "def attempt_sell_type_list(sell_region_id, sell_location_id, sell_volume, buy_order_list):\n",
    "    config = dict(use_citadel=False)\n",
    "    potential = []\n",
    "    for next_order in buy_order_list:\n",
    "        try:\n",
    "            if sell_volume >= next_order['min_volume'] and next_order['volume'] > 0 and \\\n",
    "               TradingUtil.check_range(sell_region_id, sell_location_id, next_order['location_id'], \n",
    "                                       next_order['order_range'], config):\n",
    "                # Sell into this order\n",
    "                amount = min(sell_volume, next_order['volume'])\n",
    "                order_record = dict(price=next_order['price'], volume=amount, market=True)\n",
    "                sell_volume -= amount\n",
    "                next_order['volume'] -= amount\n",
    "                potential.append(order_record)\n",
    "        except:\n",
    "            # We'll get an exception if TradingUtil can't find the location of a player-owned\n",
    "            # station.  We'll ignore those for now.  Change \"use_citadeL\" to True above\n",
    "            # if you'd like to attempt to resolve the location of these stations from a \n",
    "            # third party source.\n",
    "            pass\n",
    "        if sell_volume == 0:\n",
    "            # We've completely filled this order\n",
    "            return potential\n",
    "    # If we never completely fill the order then return no orders\n",
    "    return []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll include a few other convenience functions to simplify our implementation\n",
    "\n",
    "# This function extracts sell orders from a snapshot based on type and station ID.\n",
    "# Recall that sell orders are sorted low price to high price in the DataFrame.\n",
    "def extract_sell_orders(snapshot, type_id, station_id):\n",
    "    by_type = snapshot[snapshot.type_id == type_id]\n",
    "    by_loc = by_type[by_type.location_id == station_id]\n",
    "    by_side = by_loc[by_loc.buy == False]\n",
    "    return [next_order[1] for next_order in by_side.iterrows()]\n",
    "\n",
    "# This function extracts buy orders from a snapshot based on type ID.\n",
    "# Recall that buy orders are sorted high price to low price in the DataFrame.\n",
    "def extract_buy_orders(snapshot, type_id):\n",
    "    by_type = snapshot[snapshot.type_id == type_id]\n",
    "    by_side = by_type[by_type.buy == True]\n",
    "    return [next_order[1] for next_order in by_side.iterrows()]\n",
    "\n",
    "# This function will combine orders by price so that the resulting\n",
    "# list has one entry for each price, with the total volume filled at\n",
    "# that price.  This compression simplifies the display of orders in\n",
    "# our output functions.\n",
    "def compress_order_list(order_list, ascending=True):\n",
    "    order_map = {}\n",
    "    market = True\n",
    "    for next_order in order_list:\n",
    "        if next_order['price'] not in order_map:\n",
    "            order_map[next_order['price']] = next_order['volume']\n",
    "        else:\n",
    "            order_map[next_order['price']] += next_order['volume']\n",
    "        market = market and next_order['market']\n",
    "    orders = [ dict(price=k,volume=v,market=market) for k, v in order_map.items()]\n",
    "    return sorted(orders, key=lambda x: x['price'], reverse=not ascending)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To determine whether we should be selling with limit orders, we need to \n",
    "# compute the \"spread return\" for a given asset.  The following function \n",
    "# does this, returning the following structure:\n",
    "#\n",
    "# {\n",
    "#   spread_return: spread return value, or 0 if none\n",
    "#   best_bid: best bid price, or None\n",
    "#   best_ask: best ask price, or None\n",
    "# }\n",
    "#\n",
    "def spread_return(snapshot, type_id, station_id, region_id):\n",
    "    # Attempt to compute best ask\n",
    "    sell_orders = extract_sell_orders(snapshot, type_id, station_id)\n",
    "    if len(sell_orders) == 0:\n",
    "        return dict(spread_return=0, best_bid=None, best_ask=None)\n",
    "    best_ask = sell_orders[0]['price']\n",
    "    # Attempt to compute best bid\n",
    "    buy_orders = extract_buy_orders(snapshot, type_id)\n",
    "    config = dict(use_citadel=False)\n",
    "    best_bid = None\n",
    "    for next_order in buy_orders:\n",
    "        try:\n",
    "            if TradingUtil.check_range(region_id, station_id, next_order['location_id'], next_order['order_range'], config):\n",
    "                best_bid = next_order['price']\n",
    "                break\n",
    "        except:\n",
    "            # We'll get an exception if TradingUtil can't find the location of a player-owned\n",
    "            # station.  We'll ignore those for now.  Change \"use_citadeL\" to True above\n",
    "            # if you'd like to attempt to resolve the location of these stations from a \n",
    "            # third party source.\n",
    "            pass\n",
    "    if best_bid is None:\n",
    "        return dict(spread_return=0, best_bid=None, best_ask=None)\n",
    "    # Return ratio data\n",
    "    return dict(spread_return=(best_ask - best_bid) / best_bid, best_bid=best_bid, best_ask=best_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is our modified opportunity attempter.  We now include the broker fee and determine whether\n",
    "# it is more profitable to sell with limit or buy orders.  As before, the result of this function \n",
    "# will be None if no opportunity was available, or an object:\n",
    "#\n",
    "# {\n",
    "#   gross: gross proceeds (total of all sales)\n",
    "#   cost: total cost (cost of buying source plus refinement costs)\n",
    "#   profit: gross - cost\n",
    "#   margin: cost / profit\n",
    "#   buy_orders: the compressed list of buy orders that were placed\n",
    "#   sell_orders: map from material type ID to the compressed list of sell orders that were placed\n",
    "# }\n",
    "#\n",
    "# Compressed order lists group orders by price and sum the volume.  Each order will now include\n",
    "# the field \"market\" which is true if the order was a market order, and false otherwise.\n",
    "#\n",
    "def attempt_opportunity(snapshot, type_id, region_id, station_id, type_map, tax_rate, efficiency, \n",
    "                        station_tax, broker_fee, market_summary, volume_limit):\n",
    "    # Compute limit order return threshold\n",
    "    limit_threshold = broker_fee / (1 - tax_rate - broker_fee)\n",
    "    # Reduce to type to extract minimum reprocessing volume\n",
    "    by_type = snapshot[snapshot.type_id == type_id]\n",
    "    required_volume = type_map[type_id]['portionSize']\n",
    "    #\n",
    "    # Create source sell order list.\n",
    "    sell_order_list = extract_sell_orders(snapshot, type_id, station_id)\n",
    "    #\n",
    "    # Create refined materials buy order lists and other maps.\n",
    "    buy_order_map = {}\n",
    "    all_sell_orders = {}\n",
    "    limit_order_max = {}\n",
    "    spread_data = {}\n",
    "    for next_mat in type_map[type_id]['material_map'].values():\n",
    "        mat_type_id = next_mat['materialTypeID']\n",
    "        # Extract the available buy orders for this material\n",
    "        buy_order_map[mat_type_id] = extract_buy_orders(snapshot, mat_type_id)\n",
    "        # Track sell orders for this material\n",
    "        all_sell_orders[mat_type_id] = []\n",
    "        # Set the total volume limit for sell limit orders for this material\n",
    "        limit_order_max[mat_type_id] = list(market_summary[market_summary.type_id == mat_type_id]['volume'])[0] * volume_limit\n",
    "        # Capture spread data for this material\n",
    "        spread_data[mat_type_id] = spread_return(snapshot, mat_type_id, station_id, region_id)\n",
    "    #\n",
    "    # Now iterate through sell orders until we stop making a profit\n",
    "    all_buy_orders = []\n",
    "    gross = 0\n",
    "    cost = 0\n",
    "    while True:\n",
    "        #\n",
    "        # Attempt to buy source material\n",
    "        current_cost = 0\n",
    "        current_gross = 0\n",
    "        bought = attempt_buy_type_list(required_volume, sell_order_list)\n",
    "        if len(bought) == 0:\n",
    "            # Can't buy any more source material, done with this opportunity\n",
    "            break\n",
    "        #\n",
    "        # Add cost of buying source material\n",
    "        current_cost = np.sum([ x['price'] * x['volume'] for x in bought ])\n",
    "        #\n",
    "        # Now attempt to refine and sell all refined materials\n",
    "        sell_orders = {}\n",
    "        for next_mat_id in buy_order_map.keys():\n",
    "            # We'll use limit orders when selling this material if the spread\n",
    "            # return exceeds the limit threshold.\n",
    "            sr_data = spread_data[next_mat_id]\n",
    "            limit_sell = sr_data['spread_return'] > limit_threshold            \n",
    "            sell_volume = int(type_map[type_id]['material_map'][next_mat_id]['quantity'] * efficiency)\n",
    "            # Either sell with limit orders or to the market\n",
    "            if limit_sell:\n",
    "                # Selling with limit orders.  Total volume may be limited.\n",
    "                amount = min(sell_volume, limit_order_max[next_mat_id])\n",
    "                if amount > 0:\n",
    "                    sold = [ dict(price=sr_data['best_ask'], volume=amount, market=False) ]\n",
    "                    limit_order_max[next_mat_id] -= amount\n",
    "                else:\n",
    "                    # We can't sell any more volume with limit orders so we're done.  An improvement\n",
    "                    # would be to now switch to market orders.  We leave this modification to the\n",
    "                    # reader.\n",
    "                    sold = []\n",
    "            else:\n",
    "                # Selling to the market\n",
    "                sold = attempt_sell_type_list(region_id, station_id, sell_volume, buy_order_map[next_mat_id])\n",
    "            if len(sold) == 0:\n",
    "                # Can't sell any more refined material, done with this opportunity\n",
    "                sell_orders = []\n",
    "                break\n",
    "            #\n",
    "            # Add gross profit from selling refined material.\n",
    "            # Include the broker fee if this was a limit sell.\n",
    "            gross_ratio = (1 - tax_rate - broker_fee) if limit_sell else (1 - tax_rate)\n",
    "            current_gross += gross_ratio * np.sum([ x['price'] * x['volume'] for x in sold ])\n",
    "            #\n",
    "            # Add incremental cost of refining source to this refined material.\n",
    "            # If we had actual adjusted_prices, we'd use those prices in place of x['price'] below.\n",
    "            current_cost += station_tax * np.sum([ x['price'] * x['volume'] for x in sold ])\n",
    "            #\n",
    "            # Save the set of sell orders we just made\n",
    "            sell_orders[next_mat_id] = sold\n",
    "        #\n",
    "        if len(sell_orders) == 0:\n",
    "            # We couldn't sell all refined material, so we're done with this opportunity\n",
    "            break\n",
    "        #\n",
    "        # Check whether we've made a profit this round.  If so, record the amounts and continue\n",
    "        if current_gross > current_cost:\n",
    "            all_buy_orders.extend(bought)\n",
    "            for i in sell_orders.keys():\n",
    "                all_sell_orders[i].extend(sell_orders[i])\n",
    "            cost += current_cost\n",
    "            gross += current_gross\n",
    "        else:\n",
    "            # This round didn't make any profit so we're done with this opportunity\n",
    "            break\n",
    "    #\n",
    "    # If we were able to make any profit, then report the opportunity\n",
    "    if gross > cost:\n",
    "        for i in all_sell_orders.keys():\n",
    "            all_sell_orders[i]=compress_order_list(all_sell_orders[i], False)\n",
    "        return dict(gross=gross, cost=cost, profit=gross - cost, margin=(gross - cost)/cost, \n",
    "                    buy_orders=compress_order_list(all_buy_orders), \n",
    "                    sell_orders=all_sell_orders)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, we can write the complete opportunity finder function\n",
    "def find_opportunities(order_book, type_map, station_id, region_id, efficiency, sales_tax, \n",
    "                       station_tax, broker_fee, market_summary, volume_limit, verbose=False):\n",
    "    total_snapshots = len(order_book.groupby(order_book.index))\n",
    "    if verbose:\n",
    "        print(\"Checking %d snapshots for opportunities\" % total_snapshots)\n",
    "    opportunities = []\n",
    "    count = 0\n",
    "    for snapshot_group in order_book.groupby(order_book.index):\n",
    "        #\n",
    "        # Each group is a pair (snapshot_time, snapshot_dataframe)\n",
    "        snapshot_time = snapshot_group[0]\n",
    "        snapshot = snapshot_group[1]\n",
    "        if verbose:\n",
    "            print(\"X\", end='')\n",
    "            count += 1\n",
    "            if count % 72 == 0:\n",
    "                print()\n",
    "        #\n",
    "        # Iterate through each source type looking for opportunities\n",
    "        for source_type in type_map.values():\n",
    "            opp = attempt_opportunity(snapshot, source_type['typeID'], region_id, station_id, type_map, \n",
    "                                      sales_tax, efficiency, station_tax, broker_fee, market_summary,\n",
    "                                      volume_limit)\n",
    "            if opp is not None:\n",
    "                #\n",
    "                # Save the time and type if we've found a valid opportunity\n",
    "                opp['time'] = snapshot_time\n",
    "                opp['type'] = source_type['typeName']\n",
    "                opportunities.append(opp)\n",
    "    if verbose:\n",
    "        print()\n",
    "    return opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 288 snapshots for opportunities\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# NOTE: this cell takes about an hour on our equipment to execute due to attempting to\n",
    "# capture all opportunities, as well as handling limit sell orders.\n",
    "#\n",
    "full_opportunities = find_opportunities(order_book, source_types, station_id, region_id, \n",
    "                                        efficiency, tax_rate, station_tax, broker_rate, \n",
    "                                        market_history, volume_limit, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As before, we will \"clean\" the opportunity list to avoid double counting.\n",
    "def clean_opportunities(opps):\n",
    "    new_opps = []\n",
    "    stamp_map = {}\n",
    "    types = set([x['type'] for x in opps])\n",
    "    # Flatten opportunites for each type\n",
    "    for next_type in types:\n",
    "        stamp_list = []\n",
    "        last = None\n",
    "        for i in [x['time'] for x in opps if x['type'] == next_type]:\n",
    "            if last is None:\n",
    "                # First opportunity\n",
    "                stamp_list.append(i)\n",
    "            elif i - last > datetime.timedelta(minutes=5):\n",
    "                # Start of new run\n",
    "                stamp_list.append(i)\n",
    "            last = i\n",
    "        stamp_map[next_type] = stamp_list\n",
    "    # Rebuild opportunities by only selecting opportunities in\n",
    "    # the flattened lists.\n",
    "    for opp in opps:\n",
    "        type = opp['type']\n",
    "        if opp['time'] in stamp_map[type]:\n",
    "            new_opps.append(opp)\n",
    "    # Return the new opportunity list\n",
    "    return new_opps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArbOpp time=2017-01-10 00:00:00  profit=      40,486.88  return=    1.15%  limit=True  type=Azure Plagioclase\n",
      "ArbOpp time=2017-01-10 00:00:00  profit=     192,659.78  return=    0.97%  limit=True  type=Rich Plagioclase\n",
      "ArbOpp time=2017-01-10 00:25:00  profit=   1,788,039.23  return=    0.88%  limit=True  type=Compressed Vitreous Mercoxit\n",
      "ArbOpp time=2017-01-10 00:55:00  profit=  45,756,239.23  return=    8.33%  limit=True  type=Compressed Triclinic Bistot\n",
      "ArbOpp time=2017-01-10 00:55:00  profit=  16,527,779.42  return=    1.83%  limit=True  type=Compressed Bright Spodumain\n",
      "ArbOpp time=2017-01-10 03:00:00  profit=  32,033,634.47  return=    5.75%  limit=True  type=Compressed Monoclinic Bistot\n",
      "ArbOpp time=2017-01-10 03:15:00  profit=      96,878.04  return=    4.80%  limit=True  type=Pristine Jaspet\n",
      "ArbOpp time=2017-01-10 03:30:00  profit=     239,188.20  return=   37.50%  limit=True  type=Vivid Hemorphite\n",
      "ArbOpp time=2017-01-10 04:10:00  profit=     233,721.18  return=   20.69%  limit=True  type=Pure Jaspet\n",
      "ArbOpp time=2017-01-10 04:10:00  profit=     108,054.77  return=    2.71%  limit=True  type=Fiery Kernite\n",
      "ArbOpp time=2017-01-10 04:10:00  profit=     359,443.15  return=    3.12%  limit=True  type=Concentrated Veldspar\n",
      "ArbOpp time=2017-01-10 05:10:00  profit=      62,823.50  return=    1.78%  limit=True  type=Azure Plagioclase\n",
      "ArbOpp time=2017-01-10 05:10:00  profit=     321,958.37  return=    1.40%  limit=True  type=Rich Plagioclase\n",
      "ArbOpp time=2017-01-10 06:50:00  profit=   5,480,411.35  return=    5.91%  limit=True  type=Compressed Gelidus\n",
      "ArbOpp time=2017-01-10 06:55:00  profit=         414.17  return=    0.02%  limit=True  type=Pure Jaspet\n",
      "ArbOpp time=2017-01-10 07:50:00  profit=         814.32  return=    2.14%  limit=True  type=Luminous Kernite\n",
      "ArbOpp time=2017-01-10 09:55:00  profit=      21,895.50  return=    0.44%  limit=True  type=Luminous Kernite\n",
      "ArbOpp time=2017-01-10 10:45:00  profit=       3,306.28  return=    2.55%  limit=True  type=Gneiss\n",
      "ArbOpp time=2017-01-10 10:55:00  profit=       6,792.09  return=    0.77%  limit=True  type=Azure Plagioclase\n",
      "ArbOpp time=2017-01-10 10:55:00  profit=       3,126.30  return=    2.14%  limit=True  type=Prismatic Gneiss\n",
      "ArbOpp time=2017-01-10 11:40:00  profit=      20,939.48  return=    1.97%  limit=True  type=Bistot\n",
      "ArbOpp time=2017-01-10 11:45:00  profit=       5,655.57  return=    0.61%  limit=True  type=Azure Plagioclase\n",
      "ArbOpp time=2017-01-10 12:00:00  profit=         276.53  return=    0.19%  limit=True  type=Prismatic Gneiss\n",
      "ArbOpp time=2017-01-10 14:05:00  profit=      69,897.48  return=    2.30%  limit=True  type=Azure Plagioclase\n",
      "ArbOpp time=2017-01-10 14:30:00  profit=      28,892.56  return=    1.15%  limit=True  type=Jaspet\n",
      "ArbOpp time=2017-01-10 17:10:00  profit=         669.20  return=    0.02%  limit=True  type=Compressed Dense Veldspar\n",
      "ArbOpp time=2017-01-10 17:35:00  profit=     553,385.90  return=    0.10%  limit=True  type=Compressed Bistot\n",
      "ArbOpp time=2017-01-10 18:05:00  profit=     912,059.31  return=    0.17%  limit=True  type=Compressed Bistot\n",
      "ArbOpp time=2017-01-10 18:10:00  profit=         946.30  return=    1.58%  limit=True  type=Glazed Hedbergite\n",
      "ArbOpp time=2017-01-10 18:40:00  profit=     828,541.28  return=    0.15%  limit=True  type=Compressed Bistot\n",
      "ArbOpp time=2017-01-10 18:45:00  profit=     103,609.73  return=   11.46%  limit=True  type=Rich Plagioclase\n",
      "ArbOpp time=2017-01-10 19:20:00  profit=      12,917.87  return=    1.32%  limit=True  type=Rich Plagioclase\n",
      "ArbOpp time=2017-01-10 20:00:00  profit=         757.00  return=    1.26%  limit=True  type=Glazed Hedbergite\n",
      "ArbOpp time=2017-01-10 20:05:00  profit=     439,762.74  return=    5.86%  limit=True  type=Vitric Hedbergite\n",
      "ArbOpp time=2017-01-10 20:25:00  profit=     113,869.14  return=    2.41%  limit=True  type=Viscous Pyroxeres\n",
      "ArbOpp time=2017-01-10 20:35:00  profit=       1,810.97  return=    0.11%  limit=True  type=Pristine Jaspet\n",
      "ArbOpp time=2017-01-10 20:55:00  profit=         983.70  return=    1.64%  limit=True  type=Glazed Hedbergite\n",
      "ArbOpp time=2017-01-10 21:20:00  profit=      42,795.55  return=    2.56%  limit=True  type=Pristine Jaspet\n",
      "ArbOpp time=2017-01-10 21:20:00  profit=      19,858.26  return=    2.02%  limit=True  type=Rich Plagioclase\n",
      "ArbOpp time=2017-01-10 21:20:00  profit=     130,689.38  return=    2.77%  limit=True  type=Concentrated Veldspar\n",
      "ArbOpp time=2017-01-10 21:35:00  profit=       8,290.72  return=    0.18%  limit=True  type=Concentrated Veldspar\n",
      "ArbOpp time=2017-01-10 23:20:00  profit=         801.45  return=    0.55%  limit=True  type=Prismatic Gneiss\n",
      "ArbOpp time=2017-01-10 23:45:00  profit=       3,884.57  return=    2.65%  limit=True  type=Prismatic Gneiss\n",
      "Total opportunities: 43\n"
     ]
    }
   ],
   "source": [
    "# Now let's look at the results including any limit order opportunities.\n",
    "cleaned_full_opps = clean_opportunities(full_opportunities)\n",
    "display_opportunities(cleaned_full_opps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of opportunities has increased as compared to the non-limit case \\(43 versus 36\\).  Also, the return per opportunity is higher in many cases.  These changes are confirmed in the aggregates we compute in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total opportunity profit: 106,578,960.92 ISK\n",
      "Total opportunity retrun: 2.62%\n"
     ]
    }
   ],
   "source": [
    "# Aggregate performance for this day with limit orders\n",
    "total_profit = np.sum([x['profit'] for x in cleaned_full_opps])\n",
    "total_cost = np.sum([x['cost'] for x in cleaned_full_opps])\n",
    "total_return = total_profit / total_cost\n",
    "print(\"Total opportunity profit: %s ISK\" % \"{:,.2f}\".format(total_profit))\n",
    "print(\"Total opportunity retrun: %s%%\" % \"{:,.2f}\".format(total_return * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Comparable numbers for the non-limit case are 47,584,077.92 ISK profit, and a return of 0.63%.  Using limit orders more than doubles our profit and more than triples return.  We've made the argument that these results are reasonable because we're dealing with highly liquid refined materials in volumes small enough to sell without difficulty.  However, a more careful analysis would consider market variance and try to predict how long it will take to fill all limit orders.  Despite our liquidity argument, it is still likely that one or more orders will need to be re-priced down in order to deal with the usual competition that occurs in the market.  Also, we've only considered a single day.  It is possible opportunities to use limit orders are relatively rare.  We leave this investigation up to the reader."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
